#include "llvm_lowering.h"
#include <string.h>
#include <assert.h>

/* Create lowering context */
LLVMLoweringContext *create_lowering_context(TensorGraph *graph, const char *output_file)
{
    LLVMLoweringContext *ctx = (LLVMLoweringContext *)malloc(sizeof(LLVMLoweringContext));
    if (!ctx)
        return NULL;

    ctx->output = fopen(output_file, "w");
    if (!ctx->output)
    {
        free(ctx);
        return NULL;
    }

    ctx->graph = graph;
    ctx->register_counter = 0;
    ctx->label_counter = 0;
    ctx->function_id = 0;

    return ctx;
}

/* Free lowering context */
void free_lowering_context(LLVMLoweringContext *ctx)
{
    if (ctx)
    {
        if (ctx->output)
            fclose(ctx->output);
        free(ctx);
    }
}

/* Get next SSA register number */
int get_next_register(LLVMLoweringContext *ctx)
{
    return ctx->register_counter++;
}

/* Get next basic block label */
int get_next_label(LLVMLoweringContext *ctx)
{
    return ctx->label_counter++;
}

/* Convert tensor dimensions to LLVM array type string */
const char *get_llvm_type_string(TensorDim *shape)
{
    static char type_str[256];
    if (!shape || shape->ndims == 0)
    {
        return "float";
    }

    // For multi-dimensional tensors: [dim0 x [dim1 x ... float]]
    snprintf(type_str, sizeof(type_str), "[%d x float]*", shape->total_size);
    return type_str;
}

/* Emit LLVM IR header with declarations */
void emit_llvm_header(LLVMLoweringContext *ctx)
{
    fprintf(ctx->output, "; ModuleID = 'tensor_compiler'\n");
    fprintf(ctx->output, "; Generated by Tensor Compiler Frontend\n");
    fprintf(ctx->output, "; Target: LLVM IR for analysis and optimization\n\n");

    fprintf(ctx->output, "target datalayout = \"e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128\"\n");
    fprintf(ctx->output, "target triple = \"x86_64-apple-macosx14.0.0\"\n\n");

    // Declare external functions for tensor operations
    fprintf(ctx->output, "; External tensor operation declarations\n");
    fprintf(ctx->output, "declare float* @tensor_alloc(i32) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_free(float*) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_matmul(float*, float*, float*, i32, i32, i32) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_add(float*, float*, float*, i32) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_mul(float*, float*, float*, i32) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_transpose(float*, float*, i32, i32) nounwind\n");
    fprintf(ctx->output, "declare float @tensor_reduce_sum(float*, i32) nounwind\n");
    fprintf(ctx->output, "declare void @tensor_print(float*, i32) nounwind\n\n");

    // Declare libc functions
    fprintf(ctx->output, "; Standard library declarations\n");
    fprintf(ctx->output, "declare i32 @printf(i8*, ...) nounwind\n");
    fprintf(ctx->output, "declare void @llvm.memcpy.p0.p0.i64(i8*, i8*, i64, i1) nounwind\n\n");
}

/* Emit LLVM IR footer */
void emit_llvm_footer(LLVMLoweringContext *ctx)
{
    fprintf(ctx->output, "\n; End of module\n");
}

/* Emit tensor declaration and allocation */
void emit_tensor_allocation(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (!node || !node->shape)
        return;

    int size = node->shape->total_size;
    int reg = get_next_register(ctx);

    fprintf(ctx->output, "  %%%d = call float* @tensor_alloc(i32 %d)", reg, size);
    fprintf(ctx->output, "  ; Allocate tensor '%s' [", node->name ? node->name : "temp");
    for (int i = 0; i < node->shape->ndims; i++)
    {
        fprintf(ctx->output, "%d", node->shape->dims[i]);
        if (i < node->shape->ndims - 1)
            fprintf(ctx->output, "x");
    }
    fprintf(ctx->output, "]\n");

    // Store register for later use
    node->node_id = reg; // Reuse node_id to track LLVM register
}

/* Emit metadata for analysis */
void emit_metadata(LLVMLoweringContext *ctx, const char *key, const char *value)
{
    fprintf(ctx->output, "  ; !%s = \"%s\"\n", key, value);
}

/* Emit analysis annotations for optimization passes */
void emit_analysis_annotations(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (!node)
        return;

    // Memory access pattern hints
    fprintf(ctx->output, "  ; !memory_access = \"");
    switch (node->op_type)
    {
    case OP_MATMUL:
        fprintf(ctx->output, "sequential_rows");
        break;
    case OP_TRANSPOSE:
        fprintf(ctx->output, "strided_columns");
        break;
    default:
        fprintf(ctx->output, "linear");
        break;
    }
    fprintf(ctx->output, "\"\n");

    // Computational intensity
    int ops = calculate_computational_cost(node);
    int mem = calculate_memory_accesses(node);
    fprintf(ctx->output, "  ; !compute_ops = %d\n", ops);
    fprintf(ctx->output, "  ; !memory_ops = %d\n", mem);
    if (mem > 0)
    {
        fprintf(ctx->output, "  ; !arithmetic_intensity = %.2f\n", (float)ops / mem);
    }
}

/* Emit matrix multiplication operation */
void emit_matmul_op(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (node->num_inputs < 2)
        return;

    GraphNode *input_a = node->inputs[0];
    GraphNode *input_b = node->inputs[1];

    // Extract dimensions (assume 2D matrices)
    int M = input_a->shape->dims[0];
    int K = input_a->shape->dims[1];
    int N = input_b->shape->dims[1];

    int out_reg = get_next_register(ctx);

    fprintf(ctx->output, "  ; Matrix multiplication: %s = %s @ %s\n",
            node->name, input_a->name, input_b->name);
    emit_analysis_annotations(ctx, node);

    fprintf(ctx->output, "  %%%d = call float* @tensor_alloc(i32 %d)\n",
            out_reg, M * N);

    fprintf(ctx->output, "  call void @tensor_matmul(float* %%%d, float* %%%d, float* %%%d, i32 %d, i32 %d, i32 %d)\n",
            out_reg, input_a->node_id, input_b->node_id, M, K, N);

    node->node_id = out_reg;
}

/* Emit element-wise operation (ADD, MUL) */
void emit_elementwise_op(LLVMLoweringContext *ctx, GraphNode *node, const char *op)
{
    if (node->num_inputs < 2)
        return;

    GraphNode *input_a = node->inputs[0];
    GraphNode *input_b = node->inputs[1];

    int size = node->shape->total_size;
    int out_reg = get_next_register(ctx);

    fprintf(ctx->output, "  ; Element-wise %s: %s = %s %s %s\n",
            op, node->name, input_a->name, op, input_b->name);
    emit_analysis_annotations(ctx, node);

    fprintf(ctx->output, "  %%%d = call float* @tensor_alloc(i32 %d)\n",
            out_reg, size);

    if (strcmp(op, "add") == 0)
    {
        fprintf(ctx->output, "  call void @tensor_add(float* %%%d, float* %%%d, float* %%%d, i32 %d)\n",
                out_reg, input_a->node_id, input_b->node_id, size);
    }
    else if (strcmp(op, "mul") == 0)
    {
        fprintf(ctx->output, "  call void @tensor_mul(float* %%%d, float* %%%d, float* %%%d, i32 %d)\n",
                out_reg, input_a->node_id, input_b->node_id, size);
    }

    node->node_id = out_reg;
}

/* Emit transpose operation */
void emit_transpose_op(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (node->num_inputs < 1)
        return;

    GraphNode *input = node->inputs[0];
    int rows = input->shape->dims[0];
    int cols = input->shape->dims[1];
    int out_reg = get_next_register(ctx);

    fprintf(ctx->output, "  ; Transpose: %s = transpose(%s)\n",
            node->name, input->name);
    emit_analysis_annotations(ctx, node);

    fprintf(ctx->output, "  %%%d = call float* @tensor_alloc(i32 %d)\n",
            out_reg, rows * cols);

    fprintf(ctx->output, "  call void @tensor_transpose(float* %%%d, float* %%%d, i32 %d, i32 %d)\n",
            out_reg, input->node_id, rows, cols);

    node->node_id = out_reg;
}

/* Emit reduce operation */
void emit_reduce_op(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (node->num_inputs < 1)
        return;

    GraphNode *input = node->inputs[0];
    int size = input->shape->total_size;
    int out_reg = get_next_register(ctx);

    fprintf(ctx->output, "  ; Reduce sum: %s = reduce_sum(%s)\n",
            node->name, input->name);
    emit_analysis_annotations(ctx, node);

    fprintf(ctx->output, "  %%%d = call float @tensor_reduce_sum(float* %%%d, i32 %d)\n",
            out_reg, input->node_id, size);

    node->node_id = out_reg;
}

/* Emit operation based on type */
void emit_operation(LLVMLoweringContext *ctx, GraphNode *node)
{
    if (!node)
        return;

    switch (node->op_type)
    {
    case OP_MATMUL:
        emit_matmul_op(ctx, node);
        break;
    case OP_ADD:
        emit_elementwise_op(ctx, node, "add");
        break;
    case OP_MUL:
        emit_elementwise_op(ctx, node, "mul");
        break;
    case OP_TRANSPOSE:
        emit_transpose_op(ctx, node);
        break;
    case OP_REDUCE:
        emit_reduce_op(ctx, node);
        break;
    case OP_IDENTITY:
        // Identity operations just reuse input register
        if (node->num_inputs > 0)
        {
            node->node_id = node->inputs[0]->node_id;
        }
        break;
    default:
        fprintf(ctx->output, "  ; Unknown operation type: %d\n", node->op_type);
        break;
    }
}

/* Emit main function that orchestrates tensor operations */
void emit_main_function(LLVMLoweringContext *ctx)
{
    fprintf(ctx->output, "\ndefine i32 @main() {\n");
    fprintf(ctx->output, "entry:\n");

    TensorGraph *graph = ctx->graph;

    // Allocate all tensors (except reduce operations which return scalars)
    fprintf(ctx->output, "  ; Tensor allocations\n");
    for (int i = 0; i < graph->num_nodes; i++)
    {
        GraphNode *node = graph->nodes[i];
        if (node && node->shape && node->op_type != OP_REDUCE)
        {
            emit_tensor_allocation(ctx, node);
        }
    }

    fprintf(ctx->output, "\n  ; Tensor operations\n");
    // Emit operations in topological order
    for (int i = 0; i < graph->num_nodes; i++)
    {
        GraphNode *node = graph->nodes[i];
        if (node && node->op_type != OP_IDENTITY)
        {
            emit_operation(ctx, node);
        }
    }

    fprintf(ctx->output, "\n  ; Cleanup\n");
    // Free allocated tensors (skip reduce operations which return scalars)
    for (int i = 0; i < graph->num_nodes; i++)
    {
        GraphNode *node = graph->nodes[i];
        if (node && node->shape && node->node_id >= 0 && node->op_type != OP_REDUCE)
        {
            fprintf(ctx->output, "  call void @tensor_free(float* %%%d)\n", node->node_id);
        }
    }

    fprintf(ctx->output, "  ret i32 0\n");
    fprintf(ctx->output, "}\n");
}

/* Main lowering function: TensorGraph -> LLVM IR */
int lower_graph_to_llvm_ir(TensorGraph *graph, const char *output_file)
{
    if (!graph || !output_file)
    {
        fprintf(stderr, "Error: Invalid graph or output file\n");
        return -1;
    }

    LLVMLoweringContext *ctx = create_lowering_context(graph, output_file);
    if (!ctx)
    {
        fprintf(stderr, "Error: Failed to create lowering context\n");
        return -1;
    }

    fprintf(stderr, "Lowering TensorGraph to LLVM IR: %s\n", output_file);
    fprintf(stderr, "  Graph nodes: %d\n", graph->num_nodes);

    // Emit IR
    emit_llvm_header(ctx);
    emit_main_function(ctx);
    emit_llvm_footer(ctx);

    free_lowering_context(ctx);

    fprintf(stderr, "✓ LLVM IR generated successfully\n");
    return 0;
}

/* Verify LLVM IR using llvm-as */
int verify_llvm_ir(const char *ll_file)
{
    char cmd[512];
    snprintf(cmd, sizeof(cmd), "llvm-as < %s > /dev/null 2>&1", ll_file);
    int ret = system(cmd);

    if (ret == 0)
    {
        fprintf(stderr, "✓ LLVM IR verification passed: %s\n", ll_file);
        return 0;
    }
    else
    {
        fprintf(stderr, "✗ LLVM IR verification failed: %s\n", ll_file);
        return -1;
    }
}
