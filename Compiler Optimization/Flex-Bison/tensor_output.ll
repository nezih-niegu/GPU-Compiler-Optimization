; ModuleID = 'tensor_compiler'
; Generated by Tensor Compiler Frontend
; Target: LLVM IR for analysis and optimization

target datalayout = "e-m:o-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"
target triple = "x86_64-apple-macosx14.0.0"

; External tensor operation declarations
declare float* @tensor_alloc(i32) nounwind
declare void @tensor_free(float*) nounwind
declare void @tensor_matmul(float*, float*, float*, i32, i32, i32) nounwind
declare void @tensor_add(float*, float*, float*, i32) nounwind
declare void @tensor_mul(float*, float*, float*, i32) nounwind
declare void @tensor_transpose(float*, float*, i32, i32) nounwind
declare float @tensor_reduce_sum(float*, i32) nounwind
declare void @tensor_print(float*, i32) nounwind

; Standard library declarations
declare i32 @printf(i8*, ...) nounwind
declare void @llvm.memcpy.p0.p0.i64(i8*, i8*, i64, i1) nounwind


define i32 @main() {
entry:
  ; Tensor allocations
  %0 = call float* @tensor_alloc(i32 243237764)  ; Allocate tensor 'ACOL' [49x4964036]
  %1 = call float* @tensor_alloc(i32 49)  ; Allocate tensor 'BCOL' [1x49]
  %2 = call float* @tensor_alloc(i32 4964036)  ; Allocate tensor 'C' [1x4964036]
  %3 = call float* @tensor_alloc(i32 5000)  ; Allocate tensor 'ACOL' [100x50]
  %4 = call float* @tensor_alloc(i32 10000)  ; Allocate tensor 'BCOL' [50x200]
  %5 = call float* @tensor_alloc(i32 20000)  ; Allocate tensor 'temp' [100x200]

  ; Tensor operations
  ; Matrix multiplication: (null) = ACOL @ BCOL
  ; !memory_access = "sequential_rows"
  ; !compute_ops = 1000000
  ; !memory_ops = 35000
  ; !arithmetic_intensity = 28.57
  %6 = call float* @tensor_alloc(i32 20000)
  call void @tensor_matmul(float* %6, float* %3, float* %4, i32 100, i32 50, i32 200)
  ; Unknown operation type: 6

  ; Cleanup
  call void @tensor_free(float* %0)
  call void @tensor_free(float* %1)
  call void @tensor_free(float* %2)
  call void @tensor_free(float* %3)
  call void @tensor_free(float* %4)
  call void @tensor_free(float* %6)
  ret i32 0
}

; End of module
